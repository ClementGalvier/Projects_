{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's define the problem statement for this project: <br> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are tasked by the State University to evaluate the attractivity of the town for future University staff relocating with their family. We will look at what the average cost of a house is, and **what are the key parameters when buying one**.<br>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sources :<br>https://edition.cnn.com/2022/02/07/success/us-housing-market-affordability-and-inventory-feseries/index.html<br>\n",
    "*Also hurt are homebuyers earning between $75,000 and $100,000. This group, the report found, can afford a maximum home price of $433,480. Researchers determined these prices by making some assumptions, including that the buyer is not spending more than 30% of their income on housing and that the purchase is financed with a 30-year fixed-rate mortgage*\n",
    "\n",
    "Sources: https://www.payscale.com/research/US/Location=Ames-IA/Salary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### To achieve this, we will run a linear regression to predict the housing prices in Ames, and we will narrow down on the 3 bedrooms, and eventually compare it with parents earnings and cost of living in Ames "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The aim is to publish these findings on a website to manage expectations for buyewrs on the hunt and provide transparency beyond the usual median price "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "from sklearn.linear_model import RidgeCV,Lasso, LassoCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import our dataset\n",
    "df = pd.read_csv('./output/df_eda_complete.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2051, 69)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we've realized that the process of exporting our df created an index\"Unammed:0\" column, let's drop it now "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Unnamed: 0'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's prepare the model for linear regression\n",
    "1. One-hot encore categorical variables\n",
    "2. Train-test-split\n",
    "3. standardize data\n",
    "4. run Linear regression + Lasso + Run Ridge | Cross validate along the way | provide the best r2\n",
    "5. Select best model\n",
    "6. Check coefficients and interpret the model\n",
    "8. answer the problem statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.Lets OHE categorical variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummify all categorical columns - pd.get_dummies is the pandas option to do one-hot encoding\n",
    "X = df.drop(columns = [\"SalePrice\"]) # get a subset_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"SalePrice\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2051, 67), (2051,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape #checking our split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#identifying categorical columns\n",
    "cat_cols = X.select_dtypes(\"object\").columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OHE dummies\n",
    "X = pd.get_dummies(X, columns=cat_cols, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2051, 224), (2051,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape #quick check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2051, 224)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 . Train-test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1640, 224), (411, 224), (1640,), (411,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape # checking outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Standardizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we will use StandardScaler to apply scaling to our entire dataset\n",
    "ss = StandardScaler()\n",
    "X_train = ss.fit_transform(X_train) # fit_transform X_train only, industry practice \n",
    "X_test = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z_train shape is: (1640, 224)\n",
      "y_train shape is: (1640,)\n",
      "Z_test shape is: (411, 224)\n",
      "y_test shape is: (411,)\n"
     ]
    }
   ],
   "source": [
    "#from the course, making sure our steps yields expected outputs\n",
    "print(f'Z_train shape is: {X_train.shape}')\n",
    "print(f'y_train shape is: {y_train.shape}')\n",
    "print(f'Z_test shape is: {X_test.shape}')\n",
    "print(f'y_test shape is: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.run Linear regression, Lasso and ridge. Cross validate along the way. select best model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's start with linear regression and see how our model performs\n",
    "#using the help of https://www.pluralsight.com/guides/linear-lasso-ridge-regression-scikit-learn to navigate\n",
    "lr = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Our model is created. let's use it to generate predictions and check their accuracy using MSE and R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19982.09257701591\n",
      "0.9362521325498426\n"
     ]
    }
   ],
   "source": [
    "pred_train_lr = lr.predict(X_train)\n",
    "print(np.sqrt(mean_squared_error(y_train,pred_train_lr)))\n",
    "print(r2_score(y_train, pred_train_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model fit on the training set seems to performs really well. let's check out on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7858805382214672.0\n",
      "-9.786231048532444e+21\n"
     ]
    }
   ],
   "source": [
    "pred_test_lr= lr.predict(X_test)\n",
    "print(np.sqrt(mean_squared_error(y_test,pred_test_lr))) \n",
    "print(r2_score(y_test, pred_test_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Baseline score** is is bad. Our model cannot generalize to new(unseen) data. means it is overfitted. let's shrinks this model using regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.7488137616592164e+25"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(lr, X_train, y_train).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== OLS =======\n",
      "R2 OLs on test is -9.786231048532444e+21\n",
      "RMSE OLS on test is 7858805382214672.0\n",
      "MAE OLS on test is 392728063868679.3\n"
     ]
    }
   ],
   "source": [
    "#baseline\n",
    "print(\" OLS \".center(18, \"=\"))# syntax: str.center(width, fillchar=' ')\n",
    "print(f'R2 OLs on test is {lr.score(X_test, y_test)}')\n",
    "print(f'RMSE OLS on test is {np.sqrt(mean_squared_error(y_test,pred_test_lr))}') \n",
    "print(f'MAE OLS on test is {metrics.mean_absolute_error(y_test, pred_test_lr)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "our cross_val_score is terrible too. We know something is wrong with this model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### On to Lasso<br>\n",
    "We want our model to be able to predict future data accurately, so we need to reduce the variance in our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#by using LASSO we apply an additional penalty term (alpha) to irrelevant features\n",
    "#we search for alphas in logspace (between 10^-2 = 0.01 and 10^0 = 1)\n",
    "l_alphas = np.logspace(-3, 1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validate over our list of Lasso alphas.\n",
    "lasso_model = LassoCV(alphas=l_alphas, cv=5, max_iter=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\galvi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1213242765.7184448, tolerance: 805335324.204708\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\galvi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2045290906.2124023, tolerance: 805335324.204708\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\galvi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2098055619.1104126, tolerance: 805335324.204708\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\galvi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2097206095.158081, tolerance: 805335324.204708\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\galvi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2095177433.8076172, tolerance: 805335324.204708\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\galvi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2094327840.4177246, tolerance: 805335324.204708\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\galvi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2094014766.5150146, tolerance: 805335324.204708\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\galvi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2093897575.0338135, tolerance: 805335324.204708\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\galvi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 843441114.9468994, tolerance: 831090403.2259413\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\galvi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1711926918.788208, tolerance: 831090403.2259413\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\galvi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1977776948.8895264, tolerance: 831090403.2259413\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\galvi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1976082238.9647217, tolerance: 831090403.2259413\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\galvi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2057812349.0787354, tolerance: 831090403.2259413\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\galvi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2060938826.5724487, tolerance: 831090403.2259413\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\galvi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2060210654.8911133, tolerance: 831090403.2259413\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\galvi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2059822057.2993164, tolerance: 831090403.2259413\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\galvi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2059668966.2403564, tolerance: 831090403.2259413\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LassoCV(alphas=array([1.00000000e-03, 2.78255940e-03, 7.74263683e-03, 2.15443469e-02,\n",
       "       5.99484250e-02, 1.66810054e-01, 4.64158883e-01, 1.29154967e+00,\n",
       "       3.59381366e+00, 1.00000000e+01]),\n",
       "        cv=5, max_iter=5000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LassoCV</label><div class=\"sk-toggleable__content\"><pre>LassoCV(alphas=array([1.00000000e-03, 2.78255940e-03, 7.74263683e-03, 2.15443469e-02,\n",
       "       5.99484250e-02, 1.66810054e-01, 4.64158883e-01, 1.29154967e+00,\n",
       "       3.59381366e+00, 1.00000000e+01]),\n",
       "        cv=5, max_iter=5000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LassoCV(alphas=array([1.00000000e-03, 2.78255940e-03, 7.74263683e-03, 2.15443469e-02,\n",
       "       5.99484250e-02, 1.66810054e-01, 4.64158883e-01, 1.29154967e+00,\n",
       "       3.59381366e+00, 1.00000000e+01]),\n",
       "        cv=5, max_iter=5000)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking model with the best alpha found in the step above\n",
    "lasso_best = Lasso(alpha =lasso_model.alpha_).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.936128683073466\n",
      "0.8620892944358395\n"
     ]
    }
   ],
   "source": [
    "#checking our model results\n",
    "print(lasso_best.score(X_train, y_train))\n",
    "print(lasso_best.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks better; lets check :\n",
    "1. which alpha was selected to be the best to improve our model\n",
    "3. what are the performance metrics for the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_model.alpha_ # checking which alpha was selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test_lasso= lasso_best.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== OLS =======\n",
      "R2 on test is -9.786231048532444e+21\n",
      "RMSE on test is 7858805382214672.0\n",
      "MAE on test is 392728063868679.3\n",
      "======LASSO ======\n",
      "R2 on test is 0.8620892944358395\n",
      "RMSE on test is 29501.750891602034\n",
      "MAE on test is 17601.691221587917\n"
     ]
    }
   ],
   "source": [
    "#baseline\n",
    "print(\" OLS \".center(18, \"=\"))# syntax: str.center(width, fillchar=' ')\n",
    "print(f'R2 on test is {lr.score(X_test, y_test)}')\n",
    "print(f'RMSE on test is {np.sqrt(mean_squared_error(y_test,pred_test_lr))}') \n",
    "print(f'MAE on test is {metrics.mean_absolute_error(y_test, pred_test_lr)}')\n",
    "\n",
    "print(\"LASSO \".center(18, \"=\"))# syntax: str.center(width, fillchar=' ')\n",
    "print(f'R2 on test is {r2_score(y_test,pred_test_lasso)}')\n",
    "print(f'RMSE on test is {np.sqrt(mean_squared_error(y_test,pred_test_lasso))}') \n",
    "print(f'MAE on test is {metrics.mean_absolute_error(y_test,pred_test_lasso)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that our model  generalizes well to new data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### On to Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiating the model\n",
    "ridge_cv = RidgeCV()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_alphas = np.logspace(0, 5, 100)\n",
    "\n",
    "# Cross-validate over our list of ridge alphas.\n",
    "# alphas: pass an Array of alpha values to try. It is still the Regularization strength\n",
    "ridge_cv = RidgeCV(alphas=r_alphas, scoring='r2', cv=5).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24272.038051756972\n",
      "0.9059418968688339\n"
     ]
    }
   ],
   "source": [
    "pred_train_rr = ridge_cv.predict(X_train) #establishing predictions for the training set\n",
    "print(np.sqrt(mean_squared_error(y_train,pred_train_rr)))#evaluating metric #1\n",
    "print(r2_score(y_train, pred_train_rr))#evaluating metric #2\n",
    "\n",
    "pred_test_rr= ridge_cv.predict(X_test)#establishing predictions for the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== OLS =======\n",
      "R2 on test is -9.786231048532444e+21\n",
      "RMSE on test is 7858805382214672.0\n",
      "MAE on test is 392728063868679.3\n",
      "======LASSO ======\n",
      "R2 on test is 0.8620892944358395\n",
      "RMSE on test is 29501.750891602034\n",
      "MAE on test is 17601.691\n",
      "======RIDGE ======\n",
      "R2 on test is 0.8670153672562568\n",
      "RMSE on test is 28970.06906158316\n",
      "MAE on test is 18373.69\n"
     ]
    }
   ],
   "source": [
    "#baseline\n",
    "print(\" OLS \".center(18, \"=\"))# syntax: str.center(width, fillchar=' ')\n",
    "print(f'R2 on test is {lr.score(X_test, y_test)}')\n",
    "print(f'RMSE on test is {np.sqrt(mean_squared_error(y_test,pred_test_lr))}') \n",
    "print(f'MAE on test is {round(metrics.mean_absolute_error(y_test, pred_test_lr),3)}')\n",
    "\n",
    "print(\"LASSO \".center(18, \"=\"))# syntax: str.center(width, fillchar=' ')\n",
    "print(f'R2 on test is {r2_score(y_test,pred_test_lasso)}')\n",
    "print(f'RMSE on test is {np.sqrt(mean_squared_error(y_test,pred_test_lasso))}') \n",
    "print(f'MAE on test is {round(metrics.mean_absolute_error(y_test,pred_test_lasso),3)}')\n",
    "\n",
    "print(\"RIDGE \".center(18, \"=\"))# syntax: str.center(width, fillchar=' ')\n",
    "print(f'R2 on test is {r2_score(y_test, pred_test_rr)}')\n",
    "print(f'RMSE on test is {np.sqrt(mean_squared_error(y_test,pred_test_rr))}') \n",
    "print(f'MAE on test is {round(metrics.mean_absolute_error(y_test,pred_test_rr),3)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we are  getting better values  with ridge, however the MAE is  lower with Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### On to Elastic net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNetCV\n",
    "\n",
    "# Set up a list of alphas to check.\n",
    "enet_alphas = np.linspace(0.5, 1.0, 100)# Return evenly spaced numbers over a specified interval\n",
    "\n",
    "# Instantiate model.\n",
    "enet_model = ElasticNetCV(alphas=enet_alphas, cv=5) #l1_ratiofloat, default=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model using optimal alpha.\n",
    "enet_model = enet_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9012777775588424\n",
      "0.8661264142981273\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions.\n",
    "enet_model_preds_train = enet_model.predict(X_train)\n",
    "enet_model_preds = enet_model.predict(X_test)\n",
    "\n",
    "\n",
    "# Evaluate model.\n",
    "print(enet_model.score(X_train, y_train))\n",
    "print(enet_model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== OLS =======\n",
      "R2 on test is -9.786231048532444e+21\n",
      "RMSE on test is 7858805382214672.0\n",
      "MAE on test is 392728063868679.3\n",
      "======LASSO ======\n",
      "R2 on test is 0.8620892944358395\n",
      "RMSE on test is 29501.750891602034\n",
      "MAE on test is 17601.691\n",
      "======RIDGE ======\n",
      "R2 on test is 0.8670153672562568\n",
      "RMSE on test is 28970.06906158316\n",
      "MAE on test is 18373.69\n",
      "======ENET =======\n",
      "R2 on test is 0.8661264142981273\n",
      "RMSE on test is 29066.734871547895\n",
      "MAE on test is 18591.85\n"
     ]
    }
   ],
   "source": [
    "#baseline\n",
    "print(\" OLS \".center(18, \"=\"))# syntax: str.center(width, fillchar=' ')\n",
    "print(f'R2 on test is {lr.score(X_test, y_test)}')\n",
    "print(f'RMSE on test is {np.sqrt(mean_squared_error(y_test,pred_test_lr))}') \n",
    "print(f'MAE on test is {round(metrics.mean_absolute_error(y_test, pred_test_lr),3)}')\n",
    "\n",
    "print(\"LASSO \".center(18, \"=\"))# syntax: str.center(width, fillchar=' ')\n",
    "print(f'R2 on test is {r2_score(y_test,pred_test_lasso)}')\n",
    "print(f'RMSE on test is {np.sqrt(mean_squared_error(y_test,pred_test_lasso))}') \n",
    "print(f'MAE on test is {round(metrics.mean_absolute_error(y_test,pred_test_lasso),3)}')\n",
    "\n",
    "print(\"RIDGE \".center(18, \"=\"))# syntax: str.center(width, fillchar=' ')\n",
    "print(f'R2 on test is {r2_score(y_test, pred_test_rr)}')\n",
    "print(f'RMSE on test is {np.sqrt(mean_squared_error(y_test,pred_test_rr))}') \n",
    "print(f'MAE on test is {round(metrics.mean_absolute_error(y_test,pred_test_rr),3)}')\n",
    "\n",
    "print(\"ENET \".center(18, \"=\"))# syntax: str.center(width, fillchar=' ')\n",
    "print(f'R2 on test is {r2_score(y_test, enet_model_preds)}')\n",
    "print(f'RMSE on test is {np.sqrt(mean_squared_error(y_test,enet_model_preds))}') \n",
    "print(f'MAE on test is {round(metrics.mean_absolute_error(y_test,enet_model_preds),3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We conclude that RIDGE provides the best regularization for our model: largest r2 lowest MEA/ RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets visualize our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>coef</th>\n",
       "      <th>abs_coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Overall Qual</td>\n",
       "      <td>9775.276887</td>\n",
       "      <td>9775.276887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Neighborhood_NridgHt</td>\n",
       "      <td>7741.695656</td>\n",
       "      <td>7741.695656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Gr Liv Area</td>\n",
       "      <td>7569.144949</td>\n",
       "      <td>7569.144949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Neighborhood_StoneBr</td>\n",
       "      <td>6055.512959</td>\n",
       "      <td>6055.512959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1st Flr SF</td>\n",
       "      <td>5185.305128</td>\n",
       "      <td>5185.305128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Garage Cars</td>\n",
       "      <td>4852.245070</td>\n",
       "      <td>4852.245070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Total Bsmt SF</td>\n",
       "      <td>4358.559418</td>\n",
       "      <td>4358.559418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2nd Flr SF</td>\n",
       "      <td>4109.740328</td>\n",
       "      <td>4109.740328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Garage Area</td>\n",
       "      <td>3977.091312</td>\n",
       "      <td>3977.091312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Mas Vnr Area</td>\n",
       "      <td>3930.947738</td>\n",
       "      <td>3930.947738</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                variable         coef     abs_coef\n",
       "3           Overall Qual  9775.276887  9775.276887\n",
       "73  Neighborhood_NridgHt  7741.695656  7741.695656\n",
       "15           Gr Liv Area  7569.144949  7569.144949\n",
       "79  Neighborhood_StoneBr  6055.512959  6055.512959\n",
       "12            1st Flr SF  5185.305128  5185.305128\n",
       "23           Garage Cars  4852.245070  4852.245070\n",
       "11         Total Bsmt SF  4358.559418  4358.559418\n",
       "13            2nd Flr SF  4109.740328  4109.740328\n",
       "24           Garage Area  3977.091312  3977.091312\n",
       "7           Mas Vnr Area  3930.947738  3930.947738"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using this visualization from Kobe solution lab\n",
    "final_ridge_df = pd.DataFrame({'variable':X.columns,\n",
    "                            'coef':ridge_cv.coef_,\n",
    "                            'abs_coef':np.abs(ridge_cv.coef_)})\n",
    "final_ridge_df.sort_values('coef', ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent variables zeroed out: 0.00048756704046806434\n"
     ]
    }
   ],
   "source": [
    "print ('Percent variables zeroed out:', np.sum((ridge_cv.coef_ == 0))/float(X.shape[0])) # checking the penalty imposed from enet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180257.36829268292\n"
     ]
    }
   ],
   "source": [
    "print(ridge_cv.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Given the table above, we can answer our problem statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are tasked by the State University to evaluate the attractivity of the town for future University staff relocating with their family. We will look at what the average cost of a house is, and what are the key parameters to consider if you're single, with kids and with cars."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key drivers of the price houses in Ames are Overall Quality, Gr Liv Area, Total Bsmt SF, 1st Floor, NridgHt Neighborhood, StoneBr and Garage Area.\n",
    "\n",
    "<br>\n",
    "\n",
    "Let's interprets the first 3: <br>\n",
    "1. The intercept is 181k, which is the average sale price. that's bizarre. We expect a minimum price but not as high as the average of the dataset\n",
    "the top 3 price predictors are Overall Quality,Gr Liv area, and whether or not the house is in NridgHt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we would recommend the university to \n",
    "1. look at tier-2 quality houses \n",
    "2. highlight the \"cheaper\" neighborhood in our model\n",
    "3. downplay the ownership of a garage (it does drive the price up with a very positive beta). Encourage staff to cycle to work "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "25a04f5bcc4cce45f88f55048bde1d1871ccb10dc4647418ede9299c65043aaf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
