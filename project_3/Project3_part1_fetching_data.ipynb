{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Problem statement`\n",
    "---\n",
    "Reddit has decided to change their business model by becoming the world's top conversation platform.\n",
    "- Reddit now want to display organic conversations from its members, but also any publicly available conversation on the internet, and classified it under one of its existing subrredits.\n",
    "\n",
    "- They have hired us to run a \"stage 0 testing\" to evaluate whether such an algorithm would even be effective based sources from reddit itself, let alone importing from other sources.\n",
    "\n",
    "**The aim of our project is to create and train a model that can correctly classify a corpus into its correct subreddit**\n",
    "\n",
    "We want to be mindful about sentiment analysis and will **create a sentiment filter** category that future reddit users will be able to use to filter for each post.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Project 3 - Part1: Fetching data`\n",
    "---\n",
    "\n",
    "In this notebook, we will \n",
    "1. [scrape reddit using the reddit API](#defining-the-function-to-fetch-data-and-pass-it-to-df)\n",
    "2. [reduce dimensionality of dataframes](#data-selection)\n",
    "3. [cleanse the data at high level ( lower/emoji, empty posts)](#data-wrangling-plan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "import requests as requests\n",
    "import regex\n",
    "\n",
    "\n",
    "import emoji\n",
    "from emoji import UNICODE_EMOJI\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Defining the function to fetch data and pass it to DF`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://api.pushshift.io/reddit/search/submission'\n",
    "\n",
    "def fetch_reddit(url,size, subreddit, iterations,first_date): #defining scope to scrape over\n",
    "    my_list=[]\n",
    "    params = {'subreddit':subreddit,'size':size,'before':first_date} #fixing timestamp param\n",
    "    for i in range(iterations):\n",
    "        response = requests.get(url,params)\n",
    "        # print(response.status_code)\n",
    "        response_extract = response.json()\n",
    "        my_list += response_extract['data'] #adding the comments to a list\n",
    "        params['before'] = my_list[-1]['created_utc']\n",
    "    return my_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetching Data from2 subreddits  + passing it to a Dataframe. <br>\n",
    "We go with 6000 extracts for each subreddit, to make sure we have enough data to play with.<br>\n",
    "Step below : we are telling the API <br>\n",
    "*go fetch batches of 200 posts from this subreddit start on Aug 30th and work backwards until you have done it 30 times*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 3.44 s\n",
      "Wall time: 5min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "function_1 = fetch_reddit('https://api.pushshift.io/reddit/search/submission/',200,'DunkinDonuts',30,1661867019) # Unix Epoch time =  Tuesday, August 30, 2022 1:43:39 PM\n",
    "function_2 = fetch_reddit('https://api.pushshift.io/reddit/search/submission/',200,'starbucks',30,1661867019) ## Unix Epoch time =  Tuesday, August 30, 2022 1:43:39 PM\n",
    "df_dunkin = pd.DataFrame(function_1) # this is the key to store function results in a dataframe!\n",
    "df_starbucks = pd.DataFrame(function_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5995 entries, 0 to 5994\n",
      "Data columns (total 77 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   all_awardings                  5995 non-null   object \n",
      " 1   allow_live_comments            5995 non-null   bool   \n",
      " 2   author                         5995 non-null   object \n",
      " 3   author_flair_css_class         0 non-null      object \n",
      " 4   author_flair_richtext          5932 non-null   object \n",
      " 5   author_flair_text              0 non-null      object \n",
      " 6   author_flair_type              5932 non-null   object \n",
      " 7   author_fullname                5932 non-null   object \n",
      " 8   author_is_blocked              4233 non-null   object \n",
      " 9   author_patreon_flair           5932 non-null   object \n",
      " 10  author_premium                 5932 non-null   object \n",
      " 11  awarders                       5995 non-null   object \n",
      " 12  can_mod_post                   5995 non-null   bool   \n",
      " 13  contest_mode                   5995 non-null   bool   \n",
      " 14  created_utc                    5995 non-null   int64  \n",
      " 15  domain                         5995 non-null   object \n",
      " 16  full_link                      5995 non-null   object \n",
      " 17  gildings                       5995 non-null   object \n",
      " 18  id                             5995 non-null   object \n",
      " 19  is_created_from_ads_ui         4820 non-null   object \n",
      " 20  is_crosspostable               5995 non-null   bool   \n",
      " 21  is_meta                        5995 non-null   bool   \n",
      " 22  is_original_content            5995 non-null   bool   \n",
      " 23  is_reddit_media_domain         5995 non-null   bool   \n",
      " 24  is_robot_indexable             5995 non-null   bool   \n",
      " 25  is_self                        5995 non-null   bool   \n",
      " 26  is_video                       5995 non-null   bool   \n",
      " 27  link_flair_background_color    5995 non-null   object \n",
      " 28  link_flair_richtext            5995 non-null   object \n",
      " 29  link_flair_text_color          5995 non-null   object \n",
      " 30  link_flair_type                5995 non-null   object \n",
      " 31  locked                         5995 non-null   bool   \n",
      " 32  media_only                     5995 non-null   bool   \n",
      " 33  no_follow                      5995 non-null   bool   \n",
      " 34  num_comments                   5995 non-null   int64  \n",
      " 35  num_crossposts                 5995 non-null   int64  \n",
      " 36  over_18                        5995 non-null   bool   \n",
      " 37  parent_whitelist_status        5995 non-null   object \n",
      " 38  permalink                      5995 non-null   object \n",
      " 39  pinned                         5995 non-null   bool   \n",
      " 40  pwls                           5995 non-null   int64  \n",
      " 41  retrieved_on                   5995 non-null   int64  \n",
      " 42  score                          5995 non-null   int64  \n",
      " 43  selftext                       5979 non-null   object \n",
      " 44  send_replies                   5995 non-null   bool   \n",
      " 45  spoiler                        5995 non-null   bool   \n",
      " 46  stickied                       5995 non-null   bool   \n",
      " 47  subreddit                      5995 non-null   object \n",
      " 48  subreddit_id                   5995 non-null   object \n",
      " 49  subreddit_subscribers          5995 non-null   int64  \n",
      " 50  subreddit_type                 5995 non-null   object \n",
      " 51  thumbnail                      5995 non-null   object \n",
      " 52  title                          5995 non-null   object \n",
      " 53  total_awards_received          5995 non-null   int64  \n",
      " 54  treatment_tags                 5995 non-null   object \n",
      " 55  upvote_ratio                   5995 non-null   float64\n",
      " 56  url                            5995 non-null   object \n",
      " 57  whitelist_status               5995 non-null   object \n",
      " 58  wls                            5995 non-null   int64  \n",
      " 59  post_hint                      1738 non-null   object \n",
      " 60  preview                        1738 non-null   object \n",
      " 61  thumbnail_height               1741 non-null   float64\n",
      " 62  thumbnail_width                1741 non-null   float64\n",
      " 63  url_overridden_by_dest         1780 non-null   object \n",
      " 64  removed_by_category            1171 non-null   object \n",
      " 65  crosspost_parent               33 non-null     object \n",
      " 66  crosspost_parent_list          33 non-null     object \n",
      " 67  author_cakeday                 20 non-null     object \n",
      " 68  author_flair_background_color  73 non-null     object \n",
      " 69  author_flair_text_color        73 non-null     object \n",
      " 70  media_metadata                 6 non-null      object \n",
      " 71  media                          64 non-null     object \n",
      " 72  media_embed                    52 non-null     object \n",
      " 73  secure_media                   64 non-null     object \n",
      " 74  secure_media_embed             52 non-null     object \n",
      " 75  banned_by                      16 non-null     object \n",
      " 76  edited                         5 non-null      float64\n",
      "dtypes: bool(18), float64(4), int64(9), object(46)\n",
      "memory usage: 2.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df_dunkin.info() # checking the size for each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6000 entries, 0 to 5999\n",
      "Data columns (total 78 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   all_awardings                  6000 non-null   object \n",
      " 1   allow_live_comments            6000 non-null   bool   \n",
      " 2   author                         6000 non-null   object \n",
      " 3   author_flair_background_color  1808 non-null   object \n",
      " 4   author_flair_css_class         1899 non-null   object \n",
      " 5   author_flair_richtext          5996 non-null   object \n",
      " 6   author_flair_template_id       1885 non-null   object \n",
      " 7   author_flair_text              1899 non-null   object \n",
      " 8   author_flair_text_color        1904 non-null   object \n",
      " 9   author_flair_type              5996 non-null   object \n",
      " 10  author_fullname                5996 non-null   object \n",
      " 11  author_is_blocked              6000 non-null   bool   \n",
      " 12  author_patreon_flair           5996 non-null   object \n",
      " 13  author_premium                 5996 non-null   object \n",
      " 14  awarders                       6000 non-null   object \n",
      " 15  can_mod_post                   6000 non-null   bool   \n",
      " 16  contest_mode                   6000 non-null   bool   \n",
      " 17  created_utc                    6000 non-null   int64  \n",
      " 18  domain                         6000 non-null   object \n",
      " 19  full_link                      6000 non-null   object \n",
      " 20  gildings                       6000 non-null   object \n",
      " 21  id                             6000 non-null   object \n",
      " 22  is_created_from_ads_ui         6000 non-null   bool   \n",
      " 23  is_crosspostable               6000 non-null   bool   \n",
      " 24  is_meta                        6000 non-null   bool   \n",
      " 25  is_original_content            6000 non-null   bool   \n",
      " 26  is_reddit_media_domain         6000 non-null   bool   \n",
      " 27  is_robot_indexable             6000 non-null   bool   \n",
      " 28  is_self                        6000 non-null   bool   \n",
      " 29  is_video                       6000 non-null   bool   \n",
      " 30  link_flair_background_color    6000 non-null   object \n",
      " 31  link_flair_richtext            6000 non-null   object \n",
      " 32  link_flair_text_color          6000 non-null   object \n",
      " 33  link_flair_type                6000 non-null   object \n",
      " 34  locked                         6000 non-null   bool   \n",
      " 35  media_only                     6000 non-null   bool   \n",
      " 36  no_follow                      6000 non-null   bool   \n",
      " 37  num_comments                   6000 non-null   int64  \n",
      " 38  num_crossposts                 6000 non-null   int64  \n",
      " 39  over_18                        6000 non-null   bool   \n",
      " 40  parent_whitelist_status        6000 non-null   object \n",
      " 41  permalink                      6000 non-null   object \n",
      " 42  pinned                         6000 non-null   bool   \n",
      " 43  pwls                           6000 non-null   int64  \n",
      " 44  retrieved_on                   6000 non-null   int64  \n",
      " 45  score                          6000 non-null   int64  \n",
      " 46  selftext                       5999 non-null   object \n",
      " 47  send_replies                   6000 non-null   bool   \n",
      " 48  spoiler                        6000 non-null   bool   \n",
      " 49  stickied                       6000 non-null   bool   \n",
      " 50  subreddit                      6000 non-null   object \n",
      " 51  subreddit_id                   6000 non-null   object \n",
      " 52  subreddit_subscribers          6000 non-null   int64  \n",
      " 53  subreddit_type                 6000 non-null   object \n",
      " 54  thumbnail                      6000 non-null   object \n",
      " 55  title                          6000 non-null   object \n",
      " 56  total_awards_received          6000 non-null   int64  \n",
      " 57  treatment_tags                 6000 non-null   object \n",
      " 58  upvote_ratio                   6000 non-null   float64\n",
      " 59  url                            6000 non-null   object \n",
      " 60  whitelist_status               6000 non-null   object \n",
      " 61  wls                            6000 non-null   int64  \n",
      " 62  removed_by_category            585 non-null    object \n",
      " 63  gallery_data                   248 non-null    object \n",
      " 64  is_gallery                     264 non-null    object \n",
      " 65  media_metadata                 262 non-null    object \n",
      " 66  thumbnail_height               1710 non-null   float64\n",
      " 67  thumbnail_width                1710 non-null   float64\n",
      " 68  url_overridden_by_dest         1723 non-null   object \n",
      " 69  post_hint                      1462 non-null   object \n",
      " 70  preview                        1462 non-null   object \n",
      " 71  author_cakeday                 22 non-null     object \n",
      " 72  poll_data                      31 non-null     object \n",
      " 73  media                          19 non-null     object \n",
      " 74  media_embed                    19 non-null     object \n",
      " 75  secure_media                   19 non-null     object \n",
      " 76  secure_media_embed             19 non-null     object \n",
      " 77  banned_by                      1 non-null      object \n",
      "dtypes: bool(20), float64(3), int64(9), object(46)\n",
      "memory usage: 2.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df_starbucks.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Data selection`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "77 features, but only 2 or 3 will be useful to predict the origin of the post:<br>\n",
    "We select  selftext and title as explanatory variable + the subreddit column<br>\n",
    "We merge both df into one for easier data manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_starbucks = df_starbucks[['subreddit','selftext','title']]\n",
    "df_dunkin = df_dunkin[['subreddit','selftext','title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat = pd.concat([df_dunkin,df_starbucks]) # merging both files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11995, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_concat.shape # checking new df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Data wrangling plan`\n",
    "---\n",
    "- Transform to lower\n",
    "- Remove empty posts\n",
    "- Remove emojis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Transform to lower\n",
    "Why we are doing this:Your model might treat a word which is in the beginning of a sentence with a capital letter different from the same word which appears later in the sentence but without any capital latter. This might lead to decline in the accuracy.<br>\n",
    "*https://stackoverflow.com/questions/45855160/nlp-when-to-lowercase-text-during-preprocessing*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat['selftext'] = df_concat['selftext'].str.lower()\n",
    "df_concat['title'] = df_concat['title'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove empty and 100< chars posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we trim posts that have self-text less than 100 char, which eleminates '[REMOVED]', but also simple \n",
    "#hyperlinks that do not provide useful information\n",
    "df_concat = df_concat[df_concat['selftext'].str.len()>=100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5801, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_concat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>selftext</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DunkinDonuts</td>\n",
       "      <td>pumpkin small: $1.99\\n\\noriginal small: $2.29\\...</td>\n",
       "      <td>how come the pumpkin coffee is less expensive ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DunkinDonuts</td>\n",
       "      <td>a few weeks ago someone posted a comment about...</td>\n",
       "      <td>dunkin app zip code issue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DunkinDonuts</td>\n",
       "      <td>our nearest dunkin is a bit of a drive, and th...</td>\n",
       "      <td>can you buy the unsweetened flavors dunkin uses?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DunkinDonuts</td>\n",
       "      <td>how do i ask for an extra shot of flavor in th...</td>\n",
       "      <td>mobile app ordering question</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DunkinDonuts</td>\n",
       "      <td>i‚Äôve used a can of monster and a variable amou...</td>\n",
       "      <td>monster energy punch at home</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      subreddit                                           selftext  \\\n",
       "0  DunkinDonuts  pumpkin small: $1.99\\n\\noriginal small: $2.29\\...   \n",
       "1  DunkinDonuts  a few weeks ago someone posted a comment about...   \n",
       "6  DunkinDonuts  our nearest dunkin is a bit of a drive, and th...   \n",
       "7  DunkinDonuts  how do i ask for an extra shot of flavor in th...   \n",
       "8  DunkinDonuts  i‚Äôve used a can of monster and a variable amou...   \n",
       "\n",
       "                                               title  \n",
       "0  how come the pumpkin coffee is less expensive ...  \n",
       "1                          dunkin app zip code issue  \n",
       "6   can you buy the unsweetened flavors dunkin uses?  \n",
       "7                       mobile app ordering question  \n",
       "8                       monster energy punch at home  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_concat.head() # we need to reset the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we see that the index have been changed with the concat\n",
    "# reseting indexes to be able to iterate over them\n",
    "df_concat.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat.drop(columns=['index'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>selftext</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DunkinDonuts</td>\n",
       "      <td>pumpkin small: $1.99\\n\\noriginal small: $2.29\\...</td>\n",
       "      <td>how come the pumpkin coffee is less expensive ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DunkinDonuts</td>\n",
       "      <td>a few weeks ago someone posted a comment about...</td>\n",
       "      <td>dunkin app zip code issue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DunkinDonuts</td>\n",
       "      <td>our nearest dunkin is a bit of a drive, and th...</td>\n",
       "      <td>can you buy the unsweetened flavors dunkin uses?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DunkinDonuts</td>\n",
       "      <td>how do i ask for an extra shot of flavor in th...</td>\n",
       "      <td>mobile app ordering question</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DunkinDonuts</td>\n",
       "      <td>i‚Äôve used a can of monster and a variable amou...</td>\n",
       "      <td>monster energy punch at home</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      subreddit                                           selftext  \\\n",
       "0  DunkinDonuts  pumpkin small: $1.99\\n\\noriginal small: $2.29\\...   \n",
       "1  DunkinDonuts  a few weeks ago someone posted a comment about...   \n",
       "2  DunkinDonuts  our nearest dunkin is a bit of a drive, and th...   \n",
       "3  DunkinDonuts  how do i ask for an extra shot of flavor in th...   \n",
       "4  DunkinDonuts  i‚Äôve used a can of monster and a variable amou...   \n",
       "\n",
       "                                               title  \n",
       "0  how come the pumpkin coffee is less expensive ...  \n",
       "1                          dunkin app zip code issue  \n",
       "2   can you buy the unsweetened flavors dunkin uses?  \n",
       "3                       mobile app ordering question  \n",
       "4                       monster energy punch at home  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_concat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Removing emojis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We remove Emojis as we are not focusing on sentiment, but rather word importance.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://gist.github.com/n1n9-jp/5857d7725f3b14cbc8ec3e878e4307ce\n",
    "def remove_emoji(string):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "        u\"\\U00002700-\\U000027BF\"  # Dingbats\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # Emoticons\n",
    "        u\"\\U00002600-\\U000026FF\"  # Miscellaneous Symbols\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # Miscellaneous Symbols And Pictographs\n",
    "        u\"\\U0001F900-\\U0001F9FF\"  # Supplemental Symbols and Pictographs\n",
    "        u\"\\U0001FA70-\\U0001FAFF\"  # Symbols and Pictographs Extended-A\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # Transport and Map Symbols\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#identify 1 emoji in our corpus\n",
    "def is_emoji(s):\n",
    "    count = 0\n",
    "    for emoji in UNICODE_EMOJI:\n",
    "        count += s.count(emoji)\n",
    "        if count > 1:\n",
    "            return False\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "198"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking how many emojis in our corpus\n",
    "df_concat['selftext'].apply(is_emoji).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i‚Äôve used a can of monster and a variable amount of ice with a zero sugar mixed berry powerade and it tastes almost exactly like it ü§∑üèΩ\\u200d‚ôÇÔ∏è'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #4 has one, let's print it out\n",
    "df_concat['selftext'][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i‚Äôve used a can of monster and a variable amount of ice with a zero sugar mixed berry powerade and it tastes almost exactly like it \\u200dÔ∏è'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing the replace function on index 4 \n",
    "remove_emoji(df_concat['selftext'][4]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1.02 s\n",
      "Wall time: 1.08 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(len(df_concat)):\n",
    "    df_concat['selftext'][i]=remove_emoji(str(df_concat['selftext'][i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>selftext</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DunkinDonuts</td>\n",
       "      <td>pumpkin small: $1.99\\n\\noriginal small: $2.29\\...</td>\n",
       "      <td>how come the pumpkin coffee is less expensive ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DunkinDonuts</td>\n",
       "      <td>a few weeks ago someone posted a comment about...</td>\n",
       "      <td>dunkin app zip code issue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DunkinDonuts</td>\n",
       "      <td>our nearest dunkin is a bit of a drive, and th...</td>\n",
       "      <td>can you buy the unsweetened flavors dunkin uses?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DunkinDonuts</td>\n",
       "      <td>how do i ask for an extra shot of flavor in th...</td>\n",
       "      <td>mobile app ordering question</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DunkinDonuts</td>\n",
       "      <td>i‚Äôve used a can of monster and a variable amou...</td>\n",
       "      <td>monster energy punch at home</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      subreddit                                           selftext  \\\n",
       "0  DunkinDonuts  pumpkin small: $1.99\\n\\noriginal small: $2.29\\...   \n",
       "1  DunkinDonuts  a few weeks ago someone posted a comment about...   \n",
       "2  DunkinDonuts  our nearest dunkin is a bit of a drive, and th...   \n",
       "3  DunkinDonuts  how do i ask for an extra shot of flavor in th...   \n",
       "4  DunkinDonuts  i‚Äôve used a can of monster and a variable amou...   \n",
       "\n",
       "                                               title  \n",
       "0  how come the pumpkin coffee is less expensive ...  \n",
       "1                          dunkin app zip code issue  \n",
       "2   can you buy the unsweetened flavors dunkin uses?  \n",
       "3                       mobile app ordering question  \n",
       "4                       monster energy punch at home  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_concat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i‚Äôve used a can of monster and a variable amount of ice with a zero sugar mixed berry powerade and it tastes almost exactly like it \\u200dÔ∏è'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_concat['selftext'][4] # checking that it works:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Export dataframes to CSV`\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat.to_csv('transformed_csv\\df_concat_part1.csv') # exporting the consolidated file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have collected, organized and cleaned the data to get ready for an EDA. Part2 will focus on finding trends and testing feature engineering before we model in Part3 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "25a04f5bcc4cce45f88f55048bde1d1871ccb10dc4647418ede9299c65043aaf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
